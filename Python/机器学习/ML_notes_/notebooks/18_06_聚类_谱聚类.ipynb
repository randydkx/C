{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 一.基本原理\n",
    "\n",
    "该部分参考了[《谱聚类》-刘建平](https://www.cnblogs.com/pinard/p/6221564.html#!comments)，本节会使用矩阵的特征分解，如果对相关概念模糊，可以先看看19章的PCA和LDA以及MDS，谱聚类将每个样本看作空间中的一个点，点与点之间的距离越近则权重越大，而谱聚类同样离不开“同类相近，异类相斥”的核心思想，所以需要量化“同类”的权重，使其尽可能的大，量化“异类”的权重，是其尽可能的小，所以谱聚类的核心内容两个：  \n",
    "\n",
    "（1）如何表示点与点之间的相似度权重，这里通常可以使用RBF函数，对于任意两点$x_i,x_j$，它们之间的权重可以表示为$w_{ij}=exp\\left(-\\frac{\\left|\\left|x_i-x_j\\right|\\right|_2^2}{2\\sigma^2}\\right)$  \n",
    "\n",
    "（2）如何对同类以及异类进行量化：   \n",
    "\n",
    "> （2.1）同类的权重可以简单由该类包含的样本来决定，对于类别样本点id的集合$A$，定义为$|A|:=A的大小$；   \n",
    "\n",
    ">（2.2）异类之间的权重可以定义为，$A$集合与$B$任意两点之间的权重和$W(A,B)=\\sum_{i\\in A,j\\in B}w_{ij}$\n",
    "\n",
    "离我们的优化目标还差一步了，那就是只需要一个单目标来表示同类权重尽可能大，异类权重尽可能小，将其相除即可，即最终的目标函数为：   \n",
    "\n",
    "$$\n",
    "    L(A_1,A_2,...,A_k)=\\sum_{i=1}^k\\frac{W(A_i,\\bar{A_i})}{|A_i|}\n",
    "$$  \n",
    "\n",
    "其中，$k$为类别数，即我们定义的超参数，$\\bar{A_i}$为$A_i$的补集，显然聚类任务要求$A_1,A_2,...,A_k$之间互斥且完备  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 二.优化目标推导\n",
    "我们的优化目标是从$A_1,A_2,...,A_k$的不同组合中选择使$L(A_1,A_2,...,A_k)$最小的，这显然是一个NP-Hard问题，借鉴降维的思想，我们假设这$k$聚类由$k$个指示向量来表示:$h_1,h2,...,h_k$,其中每个向量$h_j$是$n$维向量（$n$是样本量），并令：   \n",
    "\n",
    "$$\n",
    "h_{ij}=\\left\\{\\begin{matrix}\n",
    "0 & i\\notin A_j\\\\ \n",
    "\\frac{1}{\\sqrt{|A_j|}} & i\\in A_j\n",
    "\\end{matrix}\\right. j=1,2,..,k;i=1,2,...,n\n",
    "$$  \n",
    "\n",
    "所以，我们聚类指示向量之间是单位正交化的$h_i^Th_i=1,h_i^Th_j=0$，所以上面的组合问题就转换为了求指示向量的问题，让我们推导一下  \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\frac{W(A_i,\\bar{A_i})}{|A_i|}&=\\frac{1}{2}\\left(\\frac{W(A_i,\\bar{A_i})}{|A_i|}+\\frac{W(\\bar{A_i},A_i)}{|A_i|}\\right)\\\\\n",
    "&=\\frac{1}{2}(\\sum_{m\\in A_i,n\\notin A_i}\\frac{w_{mn}}{|A_i|}+\\sum_{m\\notin A_i,n\\in A_i}\\frac{w_{mn}}{|A_i|})\\\\\n",
    "&=\\frac{1}{2}\\sum_{m,n}w_{mn}(h_{mi}-h_{ni})^2\\\\\n",
    "&=h_i^TLh_i\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$  \n",
    "\n",
    "其中，$L$即是拉普拉斯矩阵，它由两部分构成:   \n",
    "\n",
    "$$\n",
    "L=D-W\n",
    "$$  \n",
    "\n",
    "这里，$D=diag(d_1,d_2,...,d_n),d_i=\\sum_{j=1}^nw_{ij}$，而$W_{ij}=w_{ij}$  \n",
    "\n",
    "所以，整体的损失函数，可以表示为：  \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "L(A_1,A_2,...,A_k)&=\\sum_{i=1}^k h_i^TLh_i\\\\\n",
    "&=tr(H^TLH)\\\\\n",
    "s.t.H^TH=I\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$  \n",
    "\n",
    "所以，$H\\in R^{n\\times k}$就是对$L$对特征分解后，由最小的$k$个特征值对应的特征向量组成，当然实际求解出的$H$未必能满足我们的期望：  \n",
    "\n",
    "$$\n",
    "h_{ij}=\\left\\{\\begin{matrix}\n",
    "0 & i\\notin A_j\\\\ \n",
    "\\frac{1}{\\sqrt{|A_j|}} & i\\in A_j\n",
    "\\end{matrix}\\right. j=1,2,..,k;i=1,2,...,n\n",
    "$$  \n",
    "\n",
    "所以，通常还需要对其进行一次聚类，比如K-means"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 三.代码实现"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import ml_models\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "X, y = make_blobs(n_samples=400, centers=4, cluster_std=0.85, random_state=0)\n",
    "X = X[:, ::-1]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/wenshuiluo/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.datasets.samples_generator module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#训练\n",
    "from ml_models.cluster import Spectral\n",
    "spectral = Spectral(n_clusters=4)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=spectral.fit_predict(X))\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 四.讨论\n",
    "\n",
    "可以发现谱聚类的灵活度很高，里面可以替换的组件很多，给了我们很大的空间，比如（1）相似矩阵的度量，可以采用其他核函数;（2）最终的聚类算法除了采用kmeans也可以尝试其他算法;（3）另外损失函数的定义还有其他方式，比如将$|A_i|$替换为$vol(A_i)$，它的定义为$vol(A_i)=\\sum_{j\\in A_i}d_j$,这也是谱聚类常用的另外一种损失函数定义，具体推导与上面的过程类似。另外由于谱聚类由相似矩阵推导而来，所以它对于稀疏矩阵比较友好，但是由于谱聚类的pipline结构，可能会由于某一组件的表现较差而影响最终的结果。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "2b0d8445d30565f6cf0731071b42a683b7aa132b1cb9bae01ff5d96fc7237cfa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}