{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.chdir('../')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 一.最大熵原理\n",
    "最大熵的思想很朴素，即将已知事实以外的未知部分看做“等可能”的，而熵是描述“等可能”大小很合适的量化指标，熵的公式如下：  \n",
    "\n",
    "$$\n",
    "H(p)=-\\sum_{i}p_i log p_i\n",
    "$$  \n",
    "\n",
    "这里分布$p$的取值有$i$种情况，每种情况的概率为$p_i$，下图绘制了二值随机变量的熵："
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "p=np.linspace(0.1,0.9,90)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "def entropy(p):\n",
    "    return -np.log(p)*p-np.log(1-p)*(1-p)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "plt.plot(p,entropy(p))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa5eea5cd30>]"
      ]
     },
     "metadata": {},
     "execution_count": 84
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 378.465625 248.518125\" width=\"378.465625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-08-09T23:00:03.638072</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 378.465625 248.518125 \nL 378.465625 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 36.465625 224.64 \nL 371.265625 224.64 \nL 371.265625 7.2 \nL 36.465625 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m31ef43691a\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.683807\" xlink:href=\"#m31ef43691a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0.1 -->\n      <g transform=\"translate(43.732244 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n        <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"89.729261\" xlink:href=\"#m31ef43691a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 0.2 -->\n      <g transform=\"translate(81.777699 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"127.774716\" xlink:href=\"#m31ef43691a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 0.3 -->\n      <g transform=\"translate(119.823153 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"165.82017\" xlink:href=\"#m31ef43691a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 0.4 -->\n      <g transform=\"translate(157.868608 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"203.865625\" xlink:href=\"#m31ef43691a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0.5 -->\n      <g transform=\"translate(195.914062 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"241.91108\" xlink:href=\"#m31ef43691a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0.6 -->\n      <g transform=\"translate(233.959517 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"279.956534\" xlink:href=\"#m31ef43691a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.7 -->\n      <g transform=\"translate(272.004972 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"318.001989\" xlink:href=\"#m31ef43691a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.8 -->\n      <g transform=\"translate(310.050426 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"356.047443\" xlink:href=\"#m31ef43691a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.9 -->\n      <g transform=\"translate(348.095881 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.984375 1.515625 \nL 10.984375 10.5 \nQ 14.703125 8.734375 18.5 7.8125 \nQ 22.3125 6.890625 25.984375 6.890625 \nQ 35.75 6.890625 40.890625 13.453125 \nQ 46.046875 20.015625 46.78125 33.40625 \nQ 43.953125 29.203125 39.59375 26.953125 \nQ 35.25 24.703125 29.984375 24.703125 \nQ 19.046875 24.703125 12.671875 31.3125 \nQ 6.296875 37.9375 6.296875 49.421875 \nQ 6.296875 60.640625 12.9375 67.421875 \nQ 19.578125 74.21875 30.609375 74.21875 \nQ 43.265625 74.21875 49.921875 64.515625 \nQ 56.59375 54.828125 56.59375 36.375 \nQ 56.59375 19.140625 48.40625 8.859375 \nQ 40.234375 -1.421875 26.421875 -1.421875 \nQ 22.703125 -1.421875 18.890625 -0.6875 \nQ 15.09375 0.046875 10.984375 1.515625 \nz\nM 30.609375 32.421875 \nQ 37.25 32.421875 41.125 36.953125 \nQ 45.015625 41.5 45.015625 49.421875 \nQ 45.015625 57.28125 41.125 61.84375 \nQ 37.25 66.40625 30.609375 66.40625 \nQ 23.96875 66.40625 20.09375 61.84375 \nQ 16.21875 57.28125 16.21875 49.421875 \nQ 16.21875 41.5 20.09375 36.953125 \nQ 23.96875 32.421875 30.609375 32.421875 \nz\n\" id=\"DejaVuSans-57\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m9a0df31a3f\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m9a0df31a3f\" y=\"201.372945\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.35 -->\n      <g transform=\"translate(7.2 205.172164)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m9a0df31a3f\" y=\"174.516975\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.40 -->\n      <g transform=\"translate(7.2 178.316194)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m9a0df31a3f\" y=\"147.661005\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.45 -->\n      <g transform=\"translate(7.2 151.460224)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m9a0df31a3f\" y=\"120.805035\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.50 -->\n      <g transform=\"translate(7.2 124.604254)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m9a0df31a3f\" y=\"93.949065\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.55 -->\n      <g transform=\"translate(7.2 97.748284)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m9a0df31a3f\" y=\"67.093095\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.60 -->\n      <g transform=\"translate(7.2 70.892314)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m9a0df31a3f\" y=\"40.237125\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 0.65 -->\n      <g transform=\"translate(7.2 44.036344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_17\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m9a0df31a3f\" y=\"13.381155\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 0.70 -->\n      <g transform=\"translate(7.2 17.180373)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_18\">\n    <path clip-path=\"url(#p0f5d4ac060)\" d=\"M 51.683807 214.756364 \nL 55.103623 204.383033 \nL 58.523439 194.457052 \nL 61.943255 184.948482 \nL 65.363071 175.831717 \nL 68.782888 167.084621 \nL 72.202704 158.687886 \nL 75.62252 150.624536 \nL 79.042336 142.879542 \nL 82.462152 135.439518 \nL 85.881968 128.292479 \nL 89.301784 121.427643 \nL 92.7216 114.835271 \nL 96.141417 108.506531 \nL 99.561233 102.433391 \nL 102.981049 96.608523 \nL 106.400865 91.025223 \nL 109.820681 85.677348 \nL 113.240497 80.559256 \nL 116.660313 75.665757 \nL 120.08013 70.99207 \nL 123.499946 66.533784 \nL 126.919762 62.286832 \nL 130.339578 58.247454 \nL 133.759394 54.41218 \nL 137.17921 50.777801 \nL 140.599026 47.341357 \nL 144.018843 44.100112 \nL 147.438659 41.051545 \nL 150.858475 38.193335 \nL 154.278291 35.523345 \nL 157.698107 33.039617 \nL 161.117923 30.740359 \nL 164.537739 28.623939 \nL 167.957556 26.688874 \nL 171.377372 24.933828 \nL 174.797188 23.3576 \nL 178.217004 21.959126 \nL 181.63682 20.737469 \nL 185.056636 19.691818 \nL 188.476452 18.821483 \nL 191.896269 18.125893 \nL 195.316085 17.604596 \nL 198.735901 17.257252 \nL 202.155717 17.083636 \nL 205.575533 17.083636 \nL 208.995349 17.257252 \nL 212.415165 17.604596 \nL 215.834981 18.125893 \nL 219.254798 18.821483 \nL 222.674614 19.691818 \nL 226.09443 20.737469 \nL 229.514246 21.959126 \nL 232.934062 23.3576 \nL 236.353878 24.933828 \nL 239.773694 26.688874 \nL 243.193511 28.623939 \nL 246.613327 30.740359 \nL 250.033143 33.039617 \nL 253.452959 35.523345 \nL 256.872775 38.193335 \nL 260.292591 41.051545 \nL 263.712407 44.100112 \nL 267.132224 47.341357 \nL 270.55204 50.777801 \nL 273.971856 54.41218 \nL 277.391672 58.247454 \nL 280.811488 62.286832 \nL 284.231304 66.533784 \nL 287.65112 70.99207 \nL 291.070937 75.665757 \nL 294.490753 80.559256 \nL 297.910569 85.677348 \nL 301.330385 91.025223 \nL 304.750201 96.608523 \nL 308.170017 102.433391 \nL 311.589833 108.506531 \nL 315.00965 114.835271 \nL 318.429466 121.427643 \nL 321.849282 128.292479 \nL 325.269098 135.439518 \nL 328.688914 142.879542 \nL 332.10873 150.624536 \nL 335.528546 158.687886 \nL 338.948362 167.084621 \nL 342.368179 175.831717 \nL 345.787995 184.948482 \nL 349.207811 194.457052 \nL 352.627627 204.383033 \nL 356.047443 214.756364 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 36.465625 224.64 \nL 36.465625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 371.265625 224.64 \nL 371.265625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 36.465625 224.64 \nL 371.265625 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 36.465625 7.2 \nL 371.265625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p0f5d4ac060\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"36.465625\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "当两者概率均为0.5时，熵取得最大值，通过最大化熵，可以使得分布更“等可能”；另外，熵还有优秀的性质，它是一个凹函数，所以最大化熵其实是一个凸问题。  \n",
    "\n",
    "对于“已知事实”，可以用约束条件来描述，比如4个值的随机变量分布，其中已知$p_1+p_2=0.4$，它的求解可以表述如下：  \n",
    "\n",
    "$$\n",
    "\\max_{p} -\\sum_{i=1}^4 p_ilogp_i \\\\\n",
    "s.t. p_1+p_2=0.4\\\\\n",
    "p_i\\geq 0,i=1,2,3,4\\\\\n",
    "\\sum_i p_i=1\n",
    "$$  \n",
    "显然，最优解为：$p_1=0.2,p_2=0.2,p_3=0.3,p_4=0.3$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 二.最大熵模型\n",
    "最大熵模型是最大熵原理在分类问题上的应用，它假设分类模型是一个条件概率分布$P(Y|X)$，即对于给定的输入$X$，以概率$P(Y|X)$输出$Y$，这时最大熵模型的目标函数定义为条件熵：  \n",
    "\n",
    "$$\n",
    "H(P)=-\\sum_{x,y}\\tilde{P}(x)P(y|x)logP(y|x)\n",
    "$$  \n",
    "\n",
    "这里，$\\tilde{P}(x)$表示边缘分布$P(X)$的经验分布，$\\tilde{P}(x)=\\frac{v(X=x)}{N}$，$v(X=x)$表示训练样本中输入$x$出现的次数，$N$表示训练样本的总数。  \n",
    "\n",
    "而最大熵模型的“已知事实”可以通过如下等式来约束：  \n",
    "\n",
    "$$\n",
    "\\sum_{x,y}\\tilde{P}(x)P(y|x)f(x,y)=\\sum_{x,y}\\tilde{P}(x,y)f(x,y)\n",
    "$$\n",
    "\n",
    "为了方便，左边式子记着$E_P(f)$，右边式子记着$E_{\\tilde{P}}(f)$，等式描述的是某函数$f(x,y)$关于模型$P(Y|X)$与经验分布$\\tilde{P}(X)$的期望与函数$f(x,y)$关于经验分布$\\tilde{P}(X,Y)$的期望相同。(这里$\\tilde{P}(x,y)=\\frac{v(X=x,Y=y)}{N}$)  \n",
    "所以重要的约束信息将由$f(x,y)$来表示，它的定义如下：  \n",
    "$$\n",
    "f(x,y)=\\left\\{\\begin{matrix}\n",
    "1 & x与y满足某一事实\\\\ \n",
    "0 & 否则\n",
    "\\end{matrix}\\right.\n",
    "$$  \n",
    "\n",
    "故最大熵模型可以理解为，模型在某些事实发生的期望和训练集相同的条件下，使得条件熵最大化。所以，对于有$n$个约束条件的最大熵模型可以表示为：  \n",
    "\n",
    "$$\n",
    "\\max_P -\\sum_{x,y}\\tilde{P}(x)P(y|x)logP(y|x) \\\\\n",
    "s.t. E_P(f_i)=E_{\\tilde{P}}(f_i),i=1,2,...,n\\\\\n",
    "\\sum_y P(y|x)=1\n",
    "$$  \n",
    "\n",
    "按照优化问题的习惯，可以改写为如下：  \n",
    "\n",
    "$$\n",
    "\\min_P \\sum_{x,y}\\tilde{P}(x)P(y|x)logP(y|x) \\\\\n",
    "s.t. E_P(f_i)-E_{\\tilde{P}}(f_i)=0,i=1,2,...,n\\\\\n",
    "\\sum_y P(y|x)-1=0\n",
    "$$  \n",
    "\n",
    "由于目标函数为凸函数，约束条件为仿射，所以我们可以通过求解对偶问题，得到原始问题的最优解，首先引入拉格朗日乘子$w_0,w_1,...,w_n$，定义拉格朗日函数$L(P,w)$：  \n",
    "\n",
    "$$\n",
    "L(P,w)=-H(P)+w_0(1-\\sum_yP(y|x)+\\sum_{i=1}^nw_i(E_{\\tilde{P}}(f_i))-E_P(f_i))\n",
    "$$  \n",
    "\n",
    "所以原问题等价于：  \n",
    "$$\n",
    "\\min_P\\max_w L(P,w)\n",
    "$$  \n",
    "它的对偶问题：  \n",
    "$$\n",
    "\\max_w\\min_P L(P,w)\n",
    "$$  \n",
    "\n",
    "首先，解里面的 $\\min_P L(P,w)$，其实对于$\\forall w$，$L(P,w)$都是关于$P$的凸函数，因为$-H(P)$是关于$P$的凸函数，而后面的$w_0(1-\\sum_yP(y|x)+\\sum_{i=1}^nw_i(E_{\\tilde{P}}(f_i))-E_P(f_i))$是关于$P(y|x)$的仿射函数，所以求$L(P,w)$对$P$的偏导数，并令其等于0，即可解得最优的$P(y|x)$,记为$P_w(y|x)$，即：  \n",
    "$$\n",
    "\\frac{\\partial L(P,w)}{\\partial P(y|x)}=\\sum_{x,y}\\tilde{P}(x)(logP(y|x)+1)-\\sum_yw_0+\\sum_{i=1}^n\\sum_{x,y}\\tilde{P}(x)f_i(x,y)w_i\\\\\n",
    "=\\sum_{x,y}\\tilde{P}(x)(logP(y|x)+1-w_0-\\sum_{i=1}^nw_if_i(x,y))\\\\\n",
    "=0\n",
    "$$  \n",
    "\n",
    "在训练集中对任意样本$\\forall x,y$，都有$\\tilde{P}(x)(logP(y|x)+1-w_0-\\sum_{i=1}^nw_if_i(x,y))=0$，显然$\\tilde{P}(x)>0$($x$本来就是训练集中的一个样本，自然概率大于0)，所以$logP(y|x)+1-w_0-\\sum_{i=1}^nw_if_i(x,y)=0$，所以：  \n",
    "$$\n",
    "P_w(y|x)=exp(\\sum_{i=1}^nw_if_i(x,y)+w_0-1)\\\\\n",
    "=\\frac{exp(\\sum_{i=1}^nw_if_i(x,y))}{exp(1-w_0)}\\\\\n",
    "    =\\frac{exp(\\sum_{i=1}^nw_if_i(x,y))}{\\sum_y exp(\\sum_{i=1}^nw_if_i(x,y))}\n",
    "$$  \n",
    "\n",
    "这就是最大熵模型的表达式（最后一步变换用到了$\\sum_y P(y|x)=1$），这里$w$即是模型的参数，聪明的童鞋其实已经发现，最大熵模型其实就是一个线性函数外面套了一个**softmax**函数，它大概就是如下图所示的这么回事：  \n",
    "![avatar](./source/05_最大熵模型.svg)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "接下来，将$L(P_w,w)$带入外层的$max$函数，即可求解最优的参数$w^*$：  \n",
    "\n",
    "$$\n",
    "w^*=arg\\max_w L(P_w,w)\n",
    "$$  \n",
    "\n",
    "推导一下模型的梯度更新公式：  \n",
    "$$\n",
    "L(P_w,w)=\\sum_{x,y}\\tilde{P}(x)P_w(y|x)logP_w(y|x)+\\sum_{i=1}^nw_i\\sum_{x,y}(\\tilde{P}(x,y)f_i(x,y)-\\tilde{P}(x)P_w(y|x)f_i(x,y))\\\\\n",
    "=\\sum_{x,y}\\tilde{P}(x,y)\\sum_{i=1}^nw_if_i(x,y)+\\sum_{x,y}\\tilde{P}(x)P_w(y|x)(logP_w(y|x)-\\sum_{i=1}^nw_if_i(x,y))\\\\\n",
    "=\\sum_{x,y}\\tilde{P}(x,y)\\sum_{i=1}^nw_if_i(x,y)-\\sum_{x,y}\\tilde{P}(x)P_w(y|x)log(\\sum_{y^{'}}exp(\\sum_{i=1}^nw_if_i(x,y^{'})))\\\\\n",
    "=\\sum_{x,y}\\tilde{P}(x,y)\\sum_{i=1}^nw_if_i(x,y)-\\sum_{x}\\tilde{P}(x)log(\\sum_{y^{'}}exp(\\sum_{i=1}^nw_if_i(x,y^{'})))\\\\\n",
    "=\\sum_{x,y}\\tilde{P}(x,y)w^Tf(x,y)-\\sum_{x}\\tilde{P}(x)log(\\sum_{y^{'}}exp(w^Tf(x,y^{'})))\n",
    "$$  \n",
    "这里，倒数第三步到倒数第二步用到了$\\sum_yP(y|x)=1$，最后一步中$w=[w_1,w_2,...,w_n]^T,f(x,y)=[f_1(x,y),f_2(x,y),...,f_n(x,y)]^T$，所以：  \n",
    "$$\n",
    "\\frac{\\partial L(P_w,w)}{\\partial w}=\\sum_{x,y}\\tilde{P}(x,y)f(x,y)-\\sum_x\\tilde{P}(x)\\frac{exp(w^Tf(x,y))f(x,y)}{\\sum_{y^{'}}exp(w^Tf(x,y^{'}))} \n",
    "$$  \n",
    "\n",
    "所以，自然$w$的更新公式：  \n",
    "$$\n",
    "w=w+\\eta\\frac{\\partial L(P_w,w)}{\\partial w}\n",
    "$$  \n",
    "这里，$\\eta$是学习率"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 三.对特征函数的进一步理解\n",
    "上面推导出了最大熵模型的梯度更新公式，想必大家对$f(x,y)$还是有点疑惑，**“满足某一事实”**这句话该如何理解？这其实与我们的学习目的相关，学习目的决定了我们的**“事实”**，比如有这样一个任务，判断“打”这个词是量词还是动词，我们收集了如下的语料：  \n",
    "\n",
    "| 句子/$x$ |  目标/$y$  |\n",
    "|-|-|\n",
    "| $x_1:$一打火柴 |  $y_1:$量词 |\n",
    "|  $x_2:$三打啤酒 |  $y_2:$量词 |\n",
    "|  $x_3:$打电话 | $y_3:$ 动词 |\n",
    "|  $x_4:$打篮球 | $y_4:$ 动词 |  \n",
    "\n",
    "通过观察，我们可以设计如下的两个特征函数来分别识别\"量词\"和\"动词\"任务：  \n",
    "$$\n",
    "f_1(x,y)=\\left\\{\\begin{matrix}\n",
    "1 & \"打\"前是数字\\\\ \n",
    "0 & 否则\n",
    "\\end{matrix}\\right.\n",
    "$$  \n",
    "\n",
    "$$\n",
    "f_2(x,y)=\\left\\{\\begin{matrix}\n",
    "1 & \"打\"后是名词，且前面无数字\\\\ \n",
    "0 & 否则\n",
    "\\end{matrix}\\right.\n",
    "$$  \n",
    "\n",
    "当然，你也可以设计这样的特征函数来做识别“量词”的任务：  \n",
    "$$\n",
    "f(x,y)=\\left\\{\\begin{matrix}\n",
    "1 & \"打\"前是\"一\",\"打\"后是\"火柴\"\\\\ \n",
    "0 & 否则\n",
    "\\end{matrix}\\right.\n",
    "$$  \n",
    "\n",
    "$$\n",
    "f(x,y)=\\left\\{\\begin{matrix}\n",
    "1 & \"打\"前是\"三\",\"打\"后是\"啤酒\"\\\\ \n",
    "0 & 否则\n",
    "\\end{matrix}\\right.\n",
    "$$  \n",
    "只是，这样的特征函数设计会使得模型学习能力变弱，比如遇到“三打火柴”，采用后面的特征函数设计就识别不出“打”是量词，而采用第一种特征函数设计就能很好的识别出来，所以要使模型具有更好的泛化能力，就需要设计更好的特征函数，而这往往依赖于人工经验，对于自然语言处理这类任务（比如上面的例子），我们可以较容易的归纳总结出一些有用的经验知识，但是对于其他情况，人工往往难以总结出一般性的规律，所以对于这些问题，我们需要设计更**“一般”**的特征函数。  \n",
    "#### 一种简单的特征函数设计\n",
    "我们可以简单考虑$x$的某个特征取某个值和$y$取某个类的组合做特征函数（对于连续型特征，可以采用分箱操作），所以我们可以设计这样两类特征函数：  \n",
    "\n",
    "（1）离散型：  \n",
    "$$\n",
    "f(x,y)=\\left\\{\\begin{matrix}\n",
    "1 & x_i=某值,y=某类\\\\ \n",
    "0 & 否则\n",
    "\\end{matrix}\\right.\n",
    "$$  \n",
    "\n",
    "（2）连续型：  \n",
    "$$\n",
    "f(x,y)=\\left\\{\\begin{matrix}\n",
    "1 & 某值1\\leq x_i< 某值2,y=某类\\\\ \n",
    "0 & 否则\n",
    "\\end{matrix}\\right.\n",
    "$$ "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    " ### 四.代码实现\n",
    "为了方便演示，首先构建训练数据和测试数据"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "# 测试\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "data = iris['data']\n",
    "target = iris['target']\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(data, target, test_size=0.2,random_state=0)\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(np.unique(y_train))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(120, 4) (120,)\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "为了方便对数据进行分箱操作，封装一个DataBinWrapper类，并对X_train和X_test进行转换（该类放到ml_models.wrapper_models中）"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "class DataBinWrapper(object):\n",
    "    def __init__(self, max_bins=10):\n",
    "        # 分段数\n",
    "        self.max_bins = max_bins\n",
    "        # 记录x各个特征的分段区间\n",
    "        self.XrangeMap = None\n",
    "\n",
    "    def fit(self, x):\n",
    "        n_sample, n_feature = x.shape\n",
    "        # 构建分段数据\n",
    "        self.XrangeMap = [[] for _ in range(0, n_feature)]\n",
    "        for index in range(0, n_feature):\n",
    "            tmp = x[:, index]\n",
    "            for percent in range(1, self.max_bins):\n",
    "                percent_value = np.percentile(tmp, (1.0 * percent / self.max_bins) * 100.0 // 1)\n",
    "                self.XrangeMap[index].append(percent_value)\n",
    "\n",
    "    def transform(self, x):\n",
    "        \"\"\"\n",
    "        抽取x_bin_index\n",
    "        :param x:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if x.ndim == 1:\n",
    "            return np.asarray([np.digitize(x[i], self.XrangeMap[i]) for i in range(0, x.size)])\n",
    "        else:\n",
    "            return np.asarray([np.digitize(x[:, i], self.XrangeMap[i]) for i in range(0, x.shape[1])]).T"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "data_bin_wrapper=DataBinWrapper(max_bins=10)\n",
    "data_bin_wrapper.fit(X_train)\n",
    "X_train=data_bin_wrapper.transform(X_train)\n",
    "X_test=data_bin_wrapper.transform(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "X_train[:5,:]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[7, 6, 8, 7],\n",
       "       [3, 5, 5, 6],\n",
       "       [2, 8, 2, 2],\n",
       "       [6, 5, 6, 7],\n",
       "       [7, 2, 8, 8]])"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "X_test[:5,:]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[5, 2, 7, 9],\n",
       "       [5, 0, 4, 3],\n",
       "       [3, 9, 1, 2],\n",
       "       [9, 3, 9, 7],\n",
       "       [1, 8, 2, 2]])"
      ]
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "由于特征函数可以有不同的形式，这里我们将特征函数解耦出来，构造一个SimpleFeatureFunction类（后续构造其他复杂的特征函数，需要定义和该类相同的函数名，该类放置到ml_models.linear_model中）"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "class SimpleFeatureFunction(object):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        记录特征函数\n",
    "        {\n",
    "            (x_index,x_value,y_index)\n",
    "        }\n",
    "        \"\"\"\n",
    "        self.feature_funcs = set()\n",
    "\n",
    "    # 构建特征函数\n",
    "    def build_feature_funcs(self, X, y):\n",
    "        n_sample, _ = X.shape\n",
    "        for index in range(0, n_sample):\n",
    "            x = X[index, :].tolist()\n",
    "            for feature_index in range(0, len(x)):\n",
    "                self.feature_funcs.add(tuple([feature_index, x[feature_index], y[index]]))\n",
    "\n",
    "    # 获取特征函数总数\n",
    "    def get_feature_funcs_num(self):\n",
    "        return len(self.feature_funcs)\n",
    "\n",
    "    # 分别命中了那几个特征函数\n",
    "    def match_feature_funcs_indices(self, x, y):\n",
    "        match_indices = []\n",
    "        index = 0\n",
    "        for feature_index, feature_value, feature_y in self.feature_funcs:\n",
    "            if feature_y == y and x[feature_index] == feature_value:\n",
    "                match_indices.append(index)\n",
    "            index += 1\n",
    "        return match_indices"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "接下来对MaxEnt类进行实现，首先实现一个softmax函数的功能(ml_models.utils)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "def softmax(x):\n",
    "    if x.ndim == 1:\n",
    "        return np.exp(x) / np.exp(x).sum()\n",
    "    else:\n",
    "        return np.exp(x) / np.exp(x).sum(axis=1, keepdims=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "进行MaxEnt类的具体实现（ml_models.linear_model）"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "from ml_models import utils\n",
    "class MaxEnt(object):\n",
    "    def __init__(self, feature_func, epochs=5, eta=0.01):\n",
    "        self.feature_func = feature_func\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "\n",
    "        self.class_num = None\n",
    "        \"\"\"\n",
    "        记录联合概率分布:\n",
    "        {\n",
    "            (x_0,x_1,...,x_p,y_index):p\n",
    "        }\n",
    "        \"\"\"\n",
    "        self.Pxy = {}\n",
    "        \"\"\"\n",
    "        记录边缘概率分布:\n",
    "        {\n",
    "            (x_0,x_1,...,x_p):p\n",
    "        }\n",
    "        \"\"\"\n",
    "        self.Px = {}\n",
    "\n",
    "        \"\"\"\n",
    "        w[i]-->feature_func[i]\n",
    "        \"\"\"\n",
    "        self.w = None\n",
    "\n",
    "    def init_params(self, X, y):\n",
    "        \"\"\"\n",
    "        初始化相应的数据\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        n_sample, n_feature = X.shape\n",
    "        self.class_num = np.max(y) + 1\n",
    "\n",
    "        # 初始化联合概率分布、边缘概率分布、特征函数\n",
    "        for index in range(0, n_sample):\n",
    "            range_indices = X[index, :].tolist()\n",
    "\n",
    "            if self.Px.get(tuple(range_indices)) is None:\n",
    "                self.Px[tuple(range_indices)] = 1\n",
    "            else:\n",
    "                self.Px[tuple(range_indices)] += 1\n",
    "\n",
    "            if self.Pxy.get(tuple(range_indices + [y[index]])) is None:\n",
    "                self.Pxy[tuple(range_indices + [y[index]])] = 1\n",
    "            else:\n",
    "                self.Pxy[tuple(range_indices + [y[index]])] += 1\n",
    "\n",
    "        for key, value in self.Pxy.items():\n",
    "            self.Pxy[key] = 1.0 * self.Pxy[key] / n_sample\n",
    "        for key, value in self.Px.items():\n",
    "            self.Px[key] = 1.0 * self.Px[key] / n_sample\n",
    "\n",
    "        # 初始化参数权重\n",
    "        self.w = np.zeros(self.feature_func.get_feature_funcs_num())\n",
    "\n",
    "    def _sum_exp_w_on_all_y(self, x):\n",
    "        \"\"\"\n",
    "        sum_y exp(self._sum_w_on_feature_funcs(x))\n",
    "        :param x:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        sum_w = 0\n",
    "        for y in range(0, self.class_num):\n",
    "            tmp_w = self._sum_exp_w_on_y(x, y)\n",
    "            sum_w += tmp_w\n",
    "        return sum_w\n",
    "\n",
    "    def _sum_exp_w_on_y(self, x, y):\n",
    "        tmp_w = 0\n",
    "        match_feature_func_indices = self.feature_func.match_feature_funcs_indices(x, y)\n",
    "        for match_feature_func_index in match_feature_func_indices:\n",
    "            tmp_w += self.w[match_feature_func_index]\n",
    "        return np.exp(tmp_w)\n",
    "    \n",
    "    def _P_w_y_conditioned_x(self,x,y):\n",
    "        return self._sum_exp_w_on_y(x,y) / (1e-7 + self._sum_exp_w_on_all_y(x))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.eta = max(1.0 / np.sqrt(X.shape[0]), self.eta)\n",
    "        self.init_params(X, y)\n",
    "        x_y = np.c_[X, y]\n",
    "        for epoch in range(self.epochs):\n",
    "            count = 0\n",
    "            np.random.shuffle(x_y)\n",
    "            for index in range(x_y.shape[0]):\n",
    "                count += 1\n",
    "                x_point = x_y[index, :-1]\n",
    "                y_point = x_y[index, -1:][0]\n",
    "                # 获取联合概率分布\n",
    "                p_xy = self.Pxy.get(tuple(x_point.tolist() + [y_point]))\n",
    "                # 获取边缘概率分布\n",
    "                p_x = self.Px.get(tuple(x_point))\n",
    "                # 更新w\n",
    "                dw = np.zeros(shape=self.w.shape)\n",
    "                match_feature_func_indices = self.feature_func.match_feature_funcs_indices(x_point, y_point)\n",
    "                if len(match_feature_func_indices) == 0:\n",
    "                    continue\n",
    "                if p_xy is not None:\n",
    "                    for match_feature_func_index in match_feature_func_indices:\n",
    "                        dw[match_feature_func_index] = p_xy\n",
    "                \n",
    "                if p_x is not None:\n",
    "                    for y_i in range(self.class_num):\n",
    "                        match_func_indices = self.feature_func.match_feature_funcs_indices(x_point,y_i)\n",
    "                        for index in match_func_indices:\n",
    "                            dw[index] -= p_x * self._P_w_y_conditioned_x(x_point,y_i)\n",
    "                # 更新\n",
    "                self.w += self.eta * dw\n",
    "                # 打印训练进度\n",
    "                if count % (X.shape[0] // 4) == 0:\n",
    "                    print(\"processing:\\tepoch:\" + str(epoch + 1) + \"/\" + str(self.epochs) + \",percent:\" + str(\n",
    "                        count) + \"/\" + str(X.shape[0]))\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        \"\"\"\n",
    "        预测为y的概率分布\n",
    "        :param x:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        y = []\n",
    "        for x_point in x:\n",
    "            y_tmp = []\n",
    "            for y_index in range(0, self.class_num):\n",
    "                match_feature_func_indices = self.feature_func.match_feature_funcs_indices(x_point, y_index)\n",
    "                tmp = 0\n",
    "                for match_feature_func_index in match_feature_func_indices:\n",
    "                    tmp += self.w[match_feature_func_index]\n",
    "                y_tmp.append(tmp)\n",
    "            y.append(y_tmp)\n",
    "        return utils.softmax(np.asarray(y))\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.argmax(self.predict_proba(x), axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "# 构建特征函数类\n",
    "feature_func=SimpleFeatureFunction()\n",
    "feature_func.build_feature_funcs(X_train,y_train)\n",
    "\n",
    "maxEnt = MaxEnt(feature_func=feature_func)\n",
    "maxEnt.fit(X_train, y_train)\n",
    "y = maxEnt.predict(X_test)\n",
    "\n",
    "print('f1:', f1_score(y_test, y, average='macro'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "processing:\tepoch:1/5,percent:30/120\n",
      "processing:\tepoch:1/5,percent:60/120\n",
      "processing:\tepoch:1/5,percent:90/120\n",
      "processing:\tepoch:1/5,percent:120/120\n",
      "processing:\tepoch:2/5,percent:30/120\n",
      "processing:\tepoch:2/5,percent:60/120\n",
      "processing:\tepoch:2/5,percent:90/120\n",
      "processing:\tepoch:2/5,percent:120/120\n",
      "processing:\tepoch:3/5,percent:30/120\n",
      "processing:\tepoch:3/5,percent:60/120\n",
      "processing:\tepoch:3/5,percent:90/120\n",
      "processing:\tepoch:3/5,percent:120/120\n",
      "processing:\tepoch:4/5,percent:30/120\n",
      "processing:\tepoch:4/5,percent:60/120\n",
      "processing:\tepoch:4/5,percent:90/120\n",
      "processing:\tepoch:4/5,percent:120/120\n",
      "processing:\tepoch:5/5,percent:30/120\n",
      "processing:\tepoch:5/5,percent:60/120\n",
      "processing:\tepoch:5/5,percent:90/120\n",
      "processing:\tepoch:5/5,percent:120/120\n",
      "f1: 0.9188034188034188\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "通过前面的分析，我们知道特征函数的复杂程度决定了模型的复杂度，下面我们添加更复杂的特征函数来增强MaxEnt的效果，上面的特征函数仅考虑了单个特征与目标的关系，我们进一步考虑二个特征与目标的关系，即：  \n",
    "\n",
    "$$\n",
    "f(x,y)=\\left\\{\\begin{matrix}\n",
    "1 & x_i=某值,x_j=某值,y=某类\\\\ \n",
    "0 & 否则\n",
    "\\end{matrix}\\right.\n",
    "$$  \n",
    "\n",
    "如此，我们可以定义一个新的UserDefineFeatureFunction类（**注意:类中的方法名称要和SimpleFeatureFunction一样**）"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "class UserDefineFeatureFunction(object):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        记录特征函数\n",
    "        {\n",
    "            (x_index1,x_value1,x_index2,x_value2,y_index)\n",
    "        }\n",
    "        \"\"\"\n",
    "        self.feature_funcs = set()\n",
    "\n",
    "    # 构建特征函数\n",
    "    def build_feature_funcs(self, X, y):\n",
    "        n_sample, _ = X.shape\n",
    "        for index in range(0, n_sample):\n",
    "            x = X[index, :].tolist()\n",
    "            for feature_index in range(0, len(x)):\n",
    "                self.feature_funcs.add(tuple([feature_index, x[feature_index], y[index]]))\n",
    "                for new_feature_index in range(0,len(x)):\n",
    "                    if feature_index!=new_feature_index:\n",
    "                        self.feature_funcs.add(tuple([feature_index, x[feature_index],new_feature_index,x[new_feature_index],y[index]]))\n",
    "\n",
    "    # 获取特征函数总数\n",
    "    def get_feature_funcs_num(self):\n",
    "        return len(self.feature_funcs)\n",
    "\n",
    "    # 分别命中了那几个特征函数\n",
    "    def match_feature_funcs_indices(self, x, y):\n",
    "        match_indices = []\n",
    "        index = 0\n",
    "        for item in self.feature_funcs:\n",
    "            if len(item)==5:\n",
    "                feature_index1, feature_value1,feature_index2,feature_value2, feature_y=item\n",
    "                if feature_y == y and x[feature_index1] == feature_value1 and x[feature_index2]==feature_value2:\n",
    "                    match_indices.append(index)\n",
    "            else:\n",
    "                feature_index1, feature_value1, feature_y=item\n",
    "                if feature_y == y and x[feature_index1] == feature_value1:\n",
    "                    match_indices.append(index)\n",
    "            index += 1\n",
    "        return match_indices"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "# 检验\n",
    "feature_func=UserDefineFeatureFunction()\n",
    "feature_func.build_feature_funcs(X_train,y_train)\n",
    "\n",
    "maxEnt = MaxEnt(feature_func=feature_func)\n",
    "maxEnt.fit(X_train, y_train)\n",
    "y = maxEnt.predict(X_test)\n",
    "\n",
    "print('f1:', f1_score(y_test, y, average='macro'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "processing:\tepoch:1/5,percent:30/120\n",
      "processing:\tepoch:1/5,percent:60/120\n",
      "processing:\tepoch:1/5,percent:90/120\n",
      "processing:\tepoch:1/5,percent:120/120\n",
      "processing:\tepoch:2/5,percent:30/120\n",
      "processing:\tepoch:2/5,percent:60/120\n",
      "processing:\tepoch:2/5,percent:90/120\n",
      "processing:\tepoch:2/5,percent:120/120\n",
      "processing:\tepoch:3/5,percent:30/120\n",
      "processing:\tepoch:3/5,percent:60/120\n",
      "processing:\tepoch:3/5,percent:90/120\n",
      "processing:\tepoch:3/5,percent:120/120\n",
      "processing:\tepoch:4/5,percent:30/120\n",
      "processing:\tepoch:4/5,percent:60/120\n",
      "processing:\tepoch:4/5,percent:90/120\n",
      "processing:\tepoch:4/5,percent:120/120\n",
      "processing:\tepoch:5/5,percent:30/120\n",
      "processing:\tepoch:5/5,percent:60/120\n",
      "processing:\tepoch:5/5,percent:90/120\n",
      "processing:\tepoch:5/5,percent:120/120\n",
      "f1: 0.957351290684624\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们可以根据自己对数据的认识，不断为模型添加一些新特征函数去增强模型的效果，只需要修改`build_feature_funcs`和`match_feature_funcs_indices`这两个函数即可（**但注意控制函数的数量规模**）  \n",
    "简单总结一下MaxEnt的优缺点，优点很明显：我们可以diy任意复杂的特征函数进去，缺点也很明显：训练很耗时，而且特征函数的设计好坏需要先验知识，对于某些任务很难直观获取"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "2b0d8445d30565f6cf0731071b42a683b7aa132b1cb9bae01ff5d96fc7237cfa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}