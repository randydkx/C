{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction <a id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I decided to learn the Conjugate Gradient Method (henceforth, CG), I read four different descriptions, which I shall politely not identify. I understood none of them. Most of them simply wrote down the method, then proved its properties without any intuitive explanation or hint of how anybody might have invented CG in the first place. This article was born of my frustration, with the wish that future students of CG will learn a rich and elegant algorithm, rather than a confusing mass of equations.\n",
    "\n",
    "CG is the most popular iterative method for solving large systems of linear equations. CG is effective for systems of the form\n",
    "\n",
    "\\begin{equation}\n",
    "Ax = b \\tag{1}\n",
    "\\end{equation}\n",
    "\n",
    "where $x$ is an unknown vector, $b$ is a known vector, and $A$ is a known, square, symmetric, positive-definite (or positive-indefinite) matrix. (Don’t worry if you’ve forgotten what “positive-definite” means; we shall review it.) These systems arise in many important settings, such as finite difference and finite element methods for solving partial differential equations, structural analysis, circuit analysis, and math homework.\n",
    "\n",
    "Iterative methods like CG are suited for use with sparse matrices. If $A$ is dense, your best course of action is probably to factor and solve the equation by backsubstitution. The time spent factoring a dense $A$ is roughly equivalent to the time spent solving the system iteratively; and once $A$ is factored, the system can be backsolved quickly for multiple values of $b$. Compare this dense matrix with a sparse matrix of larger size that fills the same amount of memory. The triangular factors of a sparse $A$ usually have many more nonzero elements than $A$ itself. Factoring may be impossible due to limited memory, and will be time-consuming as well; even the backsolving step may be slower than iterative solution. On the other hand, most iterative methods are memory-efficient and run quickly with sparse matrices.\n",
    "\n",
    "I assume that you have taken a first course in linear algebra, and that you have a solid understanding of matrix multiplication and linear independence, although you probably don’t remember what those eigenthingies were all about. From this foundation, I shall build the edifice of CG as clearly as I can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next: [2. Notation](CG02.ipynb)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
