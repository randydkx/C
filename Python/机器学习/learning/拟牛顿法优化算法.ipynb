{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# DFP算法：拟牛顿方法\n",
    "import numpy as np\n",
    "class DFP(object):\n",
    "    def __init__(self,x0,g0):\n",
    "        super().__init__()\n",
    "        self.x0 = x0\n",
    "        self.g0 = g0\n",
    "        # 初始化G0为一个单位矩阵（正定矩阵）\n",
    "        self.G0 = np.eye(len(x0))\n",
    "        \n",
    "    # 根据算法，使用下一轮的xk+1和gk+1更新矩阵Gk+1\n",
    "    def update_quasi_newton_matrix(self,x1,g1):\n",
    "        y0 = g1 - self.g0\n",
    "        delta0 = x1 - self.x0\n",
    "        self.G0 = self.G0 + delta0 @ delta0.T /( (delta0.T @ y0)[0,0] + 1e-7) - self.G0 @ y0 @ y0.T @ self.G0 / ((y0.T @ self.G0 @ y0)[0,0] + 1e-7)\n",
    "    \n",
    "    # 对原始的梯度做调整，变成牛顿方向\n",
    "    # 也就是求得更新方向的反方向\n",
    "    def adjust_gradient(self,gradient):\n",
    "        return self.G0 @ gradient"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# 使用拟牛顿法对凸函数就行最优值搜索\n",
    "\n",
    "def func(x):\n",
    "    return x[0,0]*x[0,0] + x[1,0]*x[1,0] + 1\n",
    "\n",
    "def gradient(x):\n",
    "    return np.array([[2 * x[0,0]],[2 * x[1,0]]])\n",
    "\n",
    "x = np.array([[1],[1]])\n",
    "g = gradient(x=x)\n",
    "dfp = DFP(x,g)\n",
    "for _ in range(1000):\n",
    "    dx = gradient(x)\n",
    "    dfp.update_quasi_newton_matrix(x,dx)\n",
    "    x = x - 0.05 * dfp.adjust_gradient(dx)\n",
    "    \n",
    "x,func(x)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([[5.01330576e-23],\n",
       "        [5.01330576e-23]]),\n",
       " 1.0)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# BFGS算法\n",
    "class BFGS(object):\n",
    "    def __init__(self,x0,g0):\n",
    "        super().__init__()\n",
    "        self.x0 = x0\n",
    "        self.g0 = g0\n",
    "        # 初始化G0为一个单位矩阵（正定矩阵）\n",
    "        self.B0 = np.eye(len(x0))\n",
    "        \n",
    "    # 根据算法，使用下一轮的xk+1和gk+1更新矩阵Gk+1\n",
    "    def update_quasi_newton_matrix(self,x1,g1):\n",
    "        y0 = g1 - self.g0\n",
    "        delta0 = x1 - self.x0\n",
    "        self.B0 = self.B0 + y0 @ y0.T  /( (y0.T @ delta0)[0,0] + 1e-7) - self.B0 @ delta0 @ delta0.T @ self.B0 / (( delta0.T @ self.B0 @ delta0 )[0,0] + 1e-7)\n",
    "    \n",
    "    # 对原始的梯度做调整，变成牛顿方向\n",
    "    # 也就是求得更新方向的反方向\n",
    "    def adjust_gradient(self,gradient):\n",
    "        return np.linalg.pinv(self.B0) @ gradient"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# 使用拟牛顿法对凸函数就行最优值搜索\n",
    "\n",
    "def func(x):\n",
    "    return x[0,0]*x[0,0] + x[1,0]*x[1,0] + 1\n",
    "\n",
    "def gradient(x):\n",
    "    return np.array([[2 * x[0,0]],[2 * x[1,0]]])\n",
    "\n",
    "x = np.array([[1],[1]])\n",
    "g = gradient(x=x)\n",
    "# 使用BFGS方法对梯度进行更新\n",
    "bfgs = BFGS(x,g)\n",
    "for _ in range(100):\n",
    "    dx = gradient(x)\n",
    "    bfgs.update_quasi_newton_matrix(x,dx)\n",
    "    x = x - 0.05 * bfgs.adjust_gradient(dx)\n",
    "    \n",
    "x,func(x)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([[0.00560892],\n",
       "        [0.00560892]]),\n",
       " 1.0000629200214106)"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "2b0d8445d30565f6cf0731071b42a683b7aa132b1cb9bae01ff5d96fc7237cfa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}