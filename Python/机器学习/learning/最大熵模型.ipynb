{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "# 测试\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "data = iris['data']\n",
    "target = iris['target']\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(data, target, test_size=0.2,random_state=0)\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(np.unique(y_train))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(120, 4) (120,)\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "# 数据进行分箱操作，\n",
    "#  x < a -- 0\n",
    "#  a < x < b --- 1\n",
    "# 依次类推，将连续的属性取值离散化\n",
    "class DataBinWrapper(object):\n",
    "    def __init__(self,max_bin = 10):\n",
    "        super().__init__()\n",
    "        self.max_bin = max_bin\n",
    "        self.XrangeMap = None\n",
    "    \n",
    "    def fit(self,X):\n",
    "        _ , n_features = X.shape\n",
    "        self.XrangeMap = [[] for _ in range(n_features)]\n",
    "        for index in range(0,n_features):\n",
    "            # 找出对应的属性\n",
    "            tmp = sorted(X[:,index])\n",
    "            for percent in range(1,self.max_bin):\n",
    "                # 找到相应的分位数10%-90%分位数\n",
    "                percent_value = np.percentile(tmp,(1.0 * percent / self.max_bin) * 100 // 1)\n",
    "                self.XrangeMap[index].append(percent_value)\n",
    "            self.XrangeMap[index] = sorted(list(self.XrangeMap[index]))\n",
    "    \n",
    "    def transform(self,X):\n",
    "        # 如果只有一个样本，将x的每一维都进行分箱\n",
    "        # np.digitize返回的是给的元素在列表中的索引区间，从1开始\n",
    "        if X.ndim == 1:\n",
    "            return np.asarray([np.digitize(X[i],self.XrangeMap[i]) for i in range(X.shape[0])])\n",
    "        else:\n",
    "            return np.asarray([np.digitize(X[:,i],self.XrangeMap[i]) for i in range(X.shape[1])]).T"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "# 将训练数据都进行分箱操作\n",
    "data_bin_wrapper=DataBinWrapper(max_bin=10)\n",
    "data_bin_wrapper.fit(X_train)\n",
    "X_train=data_bin_wrapper.transform(X_train)\n",
    "X_test=data_bin_wrapper.transform(X_test)\n",
    "X_train[:5,:]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[7, 6, 8, 7],\n",
       "       [3, 5, 5, 6],\n",
       "       [2, 8, 2, 2],\n",
       "       [6, 5, 6, 7],\n",
       "       [7, 2, 8, 8]])"
      ]
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "X_test[:5,:]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[5, 2, 7, 9],\n",
       "       [5, 0, 4, 3],\n",
       "       [3, 9, 1, 2],\n",
       "       [9, 3, 9, 7],\n",
       "       [1, 8, 2, 2]])"
      ]
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "class SimpleFeatureFunction(object):\n",
    "    def __init__(self):\n",
    "        self.feature_funcs=set()\n",
    "    \n",
    "    def build_feature_funcs(self,X,Y):\n",
    "        n_sample = X.shape[0]\n",
    "        # 对每个元素的每个特征区间和y构建指示函数\n",
    "        for index in range(n_sample):\n",
    "            x = X[index,:].tolist()\n",
    "            for feature_index in range(len(x)):\n",
    "                self.feature_funcs.add(tuple([feature_index,x[feature_index],Y[index]]))\n",
    "\n",
    "    def get_feature_funcs_num(self):\n",
    "        return len(self.feature_funcs)\n",
    "    \n",
    "    # 返回命中的特诊函数\n",
    "    def match_feature_function_indices(self,x,y):\n",
    "        match_indices = []\n",
    "        index = 0\n",
    "        for func in self.feature_funcs:\n",
    "            feature_index,feature_value,y_value = func\n",
    "            if y_value == y and x[feature_index]==feature_value:\n",
    "                match_indices.append(index)\n",
    "            index += 1\n",
    "        return match_indices"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "import utils\n",
    "class MaxEntropy(object):\n",
    "    def __init__(self,feature_func,epochs=5,eta=0.01):\n",
    "        super().__init__()\n",
    "        self.feature_func = feature_func\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.class_num = None # 类别数量\n",
    "        # 经验联合概率分布P_tiled(x,y)\n",
    "        self.Pxy = {}\n",
    "        # 经验边缘分布P_tiled(x)\n",
    "        self.Px = {}\n",
    "        # 每个特征函数的权重\n",
    "        self.w = None\n",
    "    \n",
    "    def init_params(self,X,Y):\n",
    "        n_sample = X.shape[0]\n",
    "        self.class_num = np.max(Y) + 1\n",
    "        \n",
    "        \n",
    "        # 初始化联合概率分布： P(x)=count(X = x) / N 和 联合概率分布P(x,y)=count(X=x,Y=y) / N\n",
    "        for index in range(n_sample):\n",
    "            range_indices = X[index,:].tolist()\n",
    "            \n",
    "            if self.Px.get(tuple(range_indices)) is None:\n",
    "                self.Px[tuple(range_indices)] = 1\n",
    "            else:\n",
    "                self.Px[tuple(range_indices)] += 1\n",
    "                \n",
    "            if self.Pxy.get(tuple(range_indices + [Y[index]])) is None:\n",
    "                self.Pxy[tuple(range_indices + [Y[index]])] = 1\n",
    "            else :\n",
    "                self.Pxy[tuple( range_indices + [Y[index]] )] += 1\n",
    "\n",
    "        for key,value in self.Px.items():\n",
    "            self.Px[key] = 1.0 * self.Px[key] / n_sample\n",
    "        for key,value in self.Pxy.items():\n",
    "            self.Pxy[key] = 1.0 * self.Pxy[key] / n_sample\n",
    "                \n",
    "        # 初始化每个特征函数的权重 \n",
    "        self.w = np.zeros(self.feature_func.get_feature_funcs_num())\n",
    "        \n",
    "    def _sum_exp_w_on_all_y(self,x):\n",
    "        sum_w = 0\n",
    "        for y in range(self.class_num):\n",
    "            tmp_exp_w = self._sum_exp_w_on_y(x,y)\n",
    "            sum_w += tmp_exp_w\n",
    "        return sum_w\n",
    "    \n",
    "    def _sum_exp_w_on_y(self,x,y):\n",
    "        tmp_w = 0\n",
    "        match_func_index = self.feature_func.match_feature_function_indices(x,y)\n",
    "        for index in match_func_index:\n",
    "            tmp_w += self.w[index]\n",
    "        return np.exp(tmp_w)\n",
    "    \n",
    "    def _P_w_y_conditioned_x(self,x,y):\n",
    "        return self._sum_exp_w_on_y(x,y) / (1e-7 + self._sum_exp_w_on_all_y(x))\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        self.eta = max(self.eta,1.0 / np.sqrt(X.shape[0]))\n",
    "        self.init_params(X,y)\n",
    "        x_y = np.c_[X,y]\n",
    "        for epoch in range(self.epochs):\n",
    "            count = 0\n",
    "            np.random.shuffle(x_y)\n",
    "            # 每个epoch内将所有样本参与w的更新\n",
    "            for index in range(x_y.shape[0]):\n",
    "                count += 1\n",
    "                x_point = x_y[index,:-1]\n",
    "                y_point = x_y[index,-1:][0]\n",
    "                # 计算经验联合概率\n",
    "                p_xy = self.Pxy.get(tuple(x_point.tolist() + [y_point]))\n",
    "                p_x = self.Px.get(tuple(x_point))\n",
    "                \n",
    "                dw = np.zeros_like(self.w)\n",
    "                \n",
    "                match_feature_func_indices = self.feature_func.match_feature_function_indices(x_point,y_point)\n",
    "                \n",
    "                if len(match_feature_func_indices) == 0:\n",
    "                    continue\n",
    "                if p_xy is not None:\n",
    "                    for index in match_feature_func_indices:\n",
    "                        dw[index] += p_xy\n",
    "                if p_x is not None:\n",
    "                    for y_i in range(self.class_num):\n",
    "                        match_func_indices = self.feature_func.match_feature_function_indices(x_point,y_i)\n",
    "                        for index in match_func_indices:\n",
    "                            dw[index] -= p_x * self._P_w_y_conditioned_x(x_point,y_i)\n",
    "                \n",
    "                # 因为是求最大值所以使用梯度上升\n",
    "                self.w = self.w + self.eta * dw\n",
    "                \n",
    "                if count % (X.shape[0] // 4) == 0:\n",
    "                    print(\"processing:\\tepoch:\" + str(epoch + 1) + \"/\" + str(self.epochs) + \",percent:\" + str(\n",
    "                        count) + \"/\" + str(X.shape[0]))\n",
    "    \n",
    "    \n",
    "    def predict_prob(self,X):\n",
    "        prob = []\n",
    "        for x_point in X:\n",
    "            y_tmp = []\n",
    "            for y in range(self.class_num):\n",
    "                y_tmp.append(self._P_w_y_conditioned_x(x_point,y))\n",
    "            prob.append(y_tmp)\n",
    "        return np.asarray(prob)    \n",
    "    \n",
    "    def predict(self,X):\n",
    "        return np.argmax(self.predict_prob(X),axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "feature_function = SimpleFeatureFunction()\n",
    "feature_function.build_feature_funcs(X_train,y_train)\n",
    "\n",
    "maxentropy = MaxEntropy(feature_func=feature_function)\n",
    "maxentropy.fit(X_train,y_train)\n",
    "y = maxentropy.predict(X_test)\n",
    "\n",
    "print('f1:',f1_score(y_test,y,average='macro'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "processing:\tepoch:1/5,percent:30/120\n",
      "processing:\tepoch:1/5,percent:60/120\n",
      "processing:\tepoch:1/5,percent:90/120\n",
      "processing:\tepoch:1/5,percent:120/120\n",
      "processing:\tepoch:2/5,percent:30/120\n",
      "processing:\tepoch:2/5,percent:60/120\n",
      "processing:\tepoch:2/5,percent:90/120\n",
      "processing:\tepoch:2/5,percent:120/120\n",
      "processing:\tepoch:3/5,percent:30/120\n",
      "processing:\tepoch:3/5,percent:60/120\n",
      "processing:\tepoch:3/5,percent:90/120\n",
      "processing:\tepoch:3/5,percent:120/120\n",
      "processing:\tepoch:4/5,percent:30/120\n",
      "processing:\tepoch:4/5,percent:60/120\n",
      "processing:\tepoch:4/5,percent:90/120\n",
      "processing:\tepoch:4/5,percent:120/120\n",
      "processing:\tepoch:5/5,percent:30/120\n",
      "processing:\tepoch:5/5,percent:60/120\n",
      "processing:\tepoch:5/5,percent:90/120\n",
      "processing:\tepoch:5/5,percent:120/120\n",
      "f1: 0.9188034188034188\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "class UserDefinedFeatureFunction(object):\n",
    "    def __init__(self):\n",
    "        self.feature_funcs = set()\n",
    "    \n",
    "    def build_feature_funcs(self,X,y):\n",
    "        n_sample = X.shape[0]\n",
    "        for index in range(n_sample):\n",
    "            x = X[index,:].tolist()\n",
    "            for feature_index in range(len(x)):\n",
    "                self.feature_funcs.add(tuple([feature_index,x[feature_index],y[index]]))\n",
    "                # 构造两个特征和y之间的关系\n",
    "                for new_feature_index in range(len(x)):\n",
    "                    if new_feature_index != feature_index:\n",
    "                        self.feature_funcs.add(tuple([feature_index,x[feature_index],new_feature_index,x[new_feature_index],y[index]]))\n",
    "                    \n",
    "    def get_feature_funcs_num(self):\n",
    "        return len(self.feature_funcs)\n",
    "    \n",
    "    # 返回命中的特诊函数\n",
    "    def match_feature_function_indices(self,x,y):\n",
    "        match_indices = []\n",
    "        for index,item in enumerate(self.feature_funcs):\n",
    "            if len(item) == 5:\n",
    "                index1,value1,index2,value2,y_value = item\n",
    "                if x[index1]==value1 and x[index2] == value2 and y == y_value:\n",
    "                    match_indices.append(index)\n",
    "            else:\n",
    "                index1,value1,y_value = item\n",
    "                if x[index1]==value1 and y == y_value:\n",
    "                    match_indices.append(index)\n",
    "        return match_indices"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "# 检验\n",
    "feature_func=UserDefinedFeatureFunction()\n",
    "feature_func.build_feature_funcs(X_train,y_train)\n",
    "\n",
    "maxEnt = MaxEntropy(feature_func=feature_func)\n",
    "maxEnt.fit(X_train, y_train)\n",
    "y = maxEnt.predict(X_test)\n",
    "\n",
    "print('f1:', f1_score(y_test, y, average='macro'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "processing:\tepoch:1/5,percent:30/120\n",
      "processing:\tepoch:1/5,percent:60/120\n",
      "processing:\tepoch:1/5,percent:90/120\n",
      "processing:\tepoch:1/5,percent:120/120\n",
      "processing:\tepoch:2/5,percent:30/120\n",
      "processing:\tepoch:2/5,percent:60/120\n",
      "processing:\tepoch:2/5,percent:90/120\n",
      "processing:\tepoch:2/5,percent:120/120\n",
      "processing:\tepoch:3/5,percent:30/120\n",
      "processing:\tepoch:3/5,percent:60/120\n",
      "processing:\tepoch:3/5,percent:90/120\n",
      "processing:\tepoch:3/5,percent:120/120\n",
      "processing:\tepoch:4/5,percent:30/120\n",
      "processing:\tepoch:4/5,percent:60/120\n",
      "processing:\tepoch:4/5,percent:90/120\n",
      "processing:\tepoch:4/5,percent:120/120\n",
      "processing:\tepoch:5/5,percent:30/120\n",
      "processing:\tepoch:5/5,percent:60/120\n",
      "processing:\tepoch:5/5,percent:90/120\n",
      "processing:\tepoch:5/5,percent:120/120\n",
      "f1: 0.957351290684624\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "print(maxEnt.feature_func.get_feature_funcs_num())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "693\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "2b0d8445d30565f6cf0731071b42a683b7aa132b1cb9bae01ff5d96fc7237cfa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}