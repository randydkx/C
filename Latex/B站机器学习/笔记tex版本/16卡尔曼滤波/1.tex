\documentclass[a4paper]{article}
\usepackage[UTF8]{ctex}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{url}
\usepackage{multirow}
\usepackage{array}
\usepackage{booktabs}
\usepackage{url}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{float}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{subfig}
\usepackage{longtable}
\usepackage{pifont}
\usepackage{color}

\allowdisplaybreaks

\geometry{a4paper, scale=0.78}

% \begin{figure}[H]
%     \centering
%     \includegraphics[width=.55\textwidth]{E.png}
%     \caption{矩阵与列向量的乘法}
%     \label{fig:my_label_1}
% \end{figure}

% \left\{
% \begin{array}{ll}
%       x+2x+z=2 & \\
%       3x+8y+z=12 & \\
%       4y+z=2
% \end{array}
% \right.

% \begin{enumerate}[itemindent = 1em, itemsep = 0.4pt, parsep=0.5pt, topsep = 0.5pt]

% \end{enumerate}

%\stackrel{a}{\longrightarrow}

%\underbrace{}_{} %下括号

%\tableofcontents %目录，并且目录页不记录页码
% \tableofcontents
% \newpage
% \setcounter{page}{1} %new page
% \clearpage

\title{Kalman Filter 01 Introduction}
\author{Chen Gong}
\date{16 January 2020}

\begin{document}
\maketitle
我们知道在概率图模型中，加入了time的因素，就得到了Dynamic Model，实际上也就说我们通常所说的State Space Model。

\textbf{如果状态是离散的}，就是我们上一节提到了Hidden Markov Model (HMM)；\textbf{如果状态是连续的}，如果状态之间的关系是线性的，就是Linear Dynamic System (Kalman Filter)，或者说是Linear Gaussian Model；如果状态之间的关系是Non-Linear的或者Non-Gaussian的，那么也就是Particle Filter。我们这一章主要描述的就是Kalman Filter。

\section{Dynamic Model Introduction}
第一类问题，Learning问题，即为在已知观测序列$O$的情况下求解$P(\pi|O)$。其中，模型可以描述为$\pi\{ \lambda,\mathcal{A},\mathcal{B} \}$。代表性的就是Hidden Markov Model。

第二类问题就是Inference问题，大致可以分为Decoding，Probability of Evidence，Filtering，Smoothing和Prediction五类问题。这里中Hidden Markov Model 05 Conclusion我们有非常详细的描述。详情可以关注Hidden Markov Model。

\section{Kalman Filtering: Linear Gaussian Model}
Filtering问题就是求$P(z_t|x_1,x_2,\cdots,x_t)$，实际上就是一个Marginal Posterior问题。对于Linear关系，Linear主要反映在相邻时刻的两个状态之间的转移关系，当前时刻的隐变量状态和观测状态之间的关系。描述如下所示：
\begin{equation}
    \begin{split}
        & z_t = A\cdot z_{t-1} + B + \epsilon \\
        & x_t = C\cdot z_{t} + D + \delta
    \end{split}
\end{equation}

$z_t,z_{t-1}$和$x_t,z_t$之间体现了线性的关系。而$\epsilon,\delta$是符合Gaussian Distribution的，$\epsilon \sim \mathcal{N}(0,Q),\delta \sim \mathcal{N}(0,R)$。所以，大家都明白了Linear和Gaussian都是从何而来的，所以Kalman Filtering被称为Linear Gaussian Model更合适。

Filtering是一类问题的总称，我们之前在Hidden Markov Model中有详细的讨论过。那么，我们回顾一下Hidden Markov Model的基本信息做一个对比。

HMM：$\lambda=\{ \pi,\mathcal{A},\mathcal{B} \}$。

状态转移矩阵：
\begin{equation}
    \begin{split}
        & A=[a_{ij}] \quad a_{ij} = P(i_{t+1}=q_j|i_t=q_i) \\
        & B=[b_j(k)] \quad b_j{k} = P(o_t=v_t|i_t=q_j)
    \end{split}
\end{equation}

那么，对于Kalman Filtering来说，状态转移矩阵，发射概率，初始矩阵，模型参数我们可以做出类似的表达：
\begin{align}
    & P(z_t|z_{t-1}) \sim \mathcal{N}(A\cdot z_{t-1} + B, Q) \\
    & P(x_t|z_{t}) \sim \mathcal{N}(C\cdot z_{t} + D, R) \\
    & z_1 \sim \mathcal{N}(\mu_1,\Sigma_1) \\
    & \theta = \{ A, B, C, D, Q, R, \mu_1, \Sigma_1 \}
\end{align}

在这一小节中，我们已经了解了基础的相关概念，那下一小节中，我们将描述了Filtering问题的建模和求解。















\end{document}
